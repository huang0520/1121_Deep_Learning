{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab10: Word2Vec\n",
    "\n",
    "link: https://nthu-datalab.github.io/ml/labs/10_Word2Vec/10_Word2Vec.html\n",
    "\n",
    "112501533 黃思誠\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 09:46:55.534130: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-02 09:46:55.534274: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-02 09:46:55.534308: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-02 09:46:55.543461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.python.keras import Input, Model\n",
    "from tensorflow.python.keras.layers import InputLayer, Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "VOCABULARY_SIZE = 50000\n",
    "DOWNLOAD_URL = \"http://mattmahoney.net/dc/\"\n",
    "DATA_PATH = \"./data\"\n",
    "FILE_NAME = \"text8.zip\"\n",
    "EXPECTED_BYTES = 31344016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "params = {\n",
    "    \"training_steps\": 40000,\n",
    "    \"skip_step\": 2000,\n",
    "    \"batch_size\": 512,\n",
    "    \"embed_size\": 512,\n",
    "    \"num_sampled\": 256,\n",
    "    \"learning_rate\": 1.0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & Get dataset dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for download and loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "def download(file_name, expected_bytes):\n",
    "    \"\"\"Download the dataset text8 if it's not already downloaded\"\"\"\n",
    "    local_file_path = os.path.join(DATA_PATH, file_name)\n",
    "    if os.path.exists(local_file_path):\n",
    "        print(\"Dataset ready\")\n",
    "        return local_file_path\n",
    "    file_name, _ = urllib.request.urlretrieve(\n",
    "        os.path.join(DOWNLOAD_URL, file_name), local_file_path\n",
    "    )\n",
    "    file_stat = os.stat(local_file_path)\n",
    "    if file_stat.st_size == expected_bytes:\n",
    "        print(\"Successfully downloaded the file\", file_name)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"File \"\n",
    "            + file_name\n",
    "            + \" might be corrupted. You should try downloading it with a browser.\"\n",
    "        )\n",
    "    return local_file_path\n",
    "\n",
    "\n",
    "# Read the data into a list of strings.\n",
    "def read_data(file_path):\n",
    "    \"\"\"Read data into a list of tokens\"\"\"\n",
    "    with zipfile.ZipFile(file_path) as f:\n",
    "        # tf.compat.as_str() converts the input into string\n",
    "        data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "    return data\n",
    "\n",
    "\n",
    "# Build the dictionary and replace rare words with UNK token.\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Create two dictionaries and count of occuring words\n",
    "    - word_to_id: map of words to their codes\n",
    "    - id_to_word: maps codes to words (inverse word_to_id)\n",
    "    - count: map of words to count of occurrences\n",
    "    \"\"\"\n",
    "    # map unknown words to -1\n",
    "    count = [[\"UNK\", -1]]\n",
    "    # count of occurences for words in vocabulary\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    word_to_id = dict()  # (word, id)\n",
    "    # record word id\n",
    "    for word, _ in count:\n",
    "        word_to_id[word] = len(word_to_id)\n",
    "    id_to_word = dict(zip(word_to_id.values(), word_to_id.keys()))  # (id, word)\n",
    "    return word_to_id, id_to_word, count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generate dataset dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_words_to_id(words, dictionary, count):\n",
    "    \"\"\"Replace each word in the dataset with its index in the dictionary\"\"\"\n",
    "    data_w2id = []\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        # return 0 if word is not in dictionary\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data_w2id.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    return data_w2id, count\n",
    "\n",
    "\n",
    "# utility function\n",
    "def generate_sample(center_words, context_window_size):\n",
    "    \"\"\"Form training pairs according to the skip-gram model.\"\"\"\n",
    "    for idx, center in enumerate(center_words):\n",
    "        context = np.random.randint(1, context_window_size)\n",
    "        # get a random target before the center word\n",
    "        for target in center_words[max(0, idx - context) : idx]:\n",
    "            yield center, target\n",
    "        # get a random target after the center word\n",
    "        for target in center_words[idx + 1 : idx + context + 1]:\n",
    "            yield center, target\n",
    "\n",
    "\n",
    "def batch_generator(data, skip_window, batch_size):\n",
    "    \"\"\"Group a numeric stream into batches and yield them as Numpy arrays.\"\"\"\n",
    "    single_gen = generate_sample(data, skip_window)\n",
    "    while True:\n",
    "        center_batch = np.zeros(batch_size, dtype=np.int32)\n",
    "        target_batch = np.zeros([batch_size, 1], dtype=np.int32)\n",
    "        for idx in range(batch_size):\n",
    "            center_batch[idx], target_batch[idx] = next(single_gen)\n",
    "        yield center_batch, target_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready\n"
     ]
    }
   ],
   "source": [
    "# Create data directory\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "# Get the dataset\n",
    "vocabulary = read_data(download(FILE_NAME, EXPECTED_BYTES))\n",
    "word_to_id, id_to_word, count = build_dataset(vocabulary, VOCABULARY_SIZE)\n",
    "data_w2id, count = convert_words_to_id(vocabulary, word_to_id, count)\n",
    "del vocabulary  # reduce memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding matrix - hidden layer\n",
    "class embedding_lookup(Layer):\n",
    "    def __init__(self, embed_size):\n",
    "        super(embedding_lookup, self).__init__()\n",
    "        embedding_init = tf.keras.initializers.GlorotUniform()\n",
    "        self.embedding_matrix = self.add_weight(\n",
    "            name=\"embedding_matrix\",\n",
    "            trainable=True,\n",
    "            shape=[VOCABULARY_SIZE, embed_size],\n",
    "            initializer=embedding_init,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        center_words = inputs\n",
    "        embedding = tf.nn.embedding_lookup(\n",
    "            self.embedding_matrix, center_words, name=\"embedding\"\n",
    "        )\n",
    "        return embedding\n",
    "\n",
    "\n",
    "# context matrix - prediction layer\n",
    "class nce_loss(Layer):\n",
    "    def __init__(self, embed_size, num_sampled):\n",
    "        super(nce_loss, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_sampled = num_sampled\n",
    "\n",
    "        nce_w_init = tf.keras.initializers.TruncatedNormal(\n",
    "            stddev=1.0 / (embed_size**0.5)\n",
    "        )\n",
    "        self.nce_weight = self.add_weight(\n",
    "            name=\"nce_weight\",\n",
    "            trainable=True,\n",
    "            shape=[VOCABULARY_SIZE, self.embed_size],\n",
    "            initializer=nce_w_init,\n",
    "        )\n",
    "        self.nce_bias = self.add_weight(\n",
    "            name=\"nce_bias\",\n",
    "            trainable=True,\n",
    "            shape=[VOCABULARY_SIZE],\n",
    "            initializer=tf.keras.initializers.Zeros,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedding, target_words = inputs[0], inputs[1]\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(\n",
    "                weights=self.nce_weight,\n",
    "                biases=self.nce_bias,\n",
    "                labels=target_words,\n",
    "                inputs=embedding,\n",
    "                num_sampled=self.num_sampled,\n",
    "                num_classes=VOCABULARY_SIZE,\n",
    "            ),\n",
    "            name=\"loss\",\n",
    "        )\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_size=512,\n",
    "        num_sampled=256,\n",
    "    ):\n",
    "        \"\"\"To-Do: Define model variables\"\"\"\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_sampled = num_sampled\n",
    "\n",
    "        # define model structure\n",
    "        self.center_words = InputLayer(\n",
    "            input_shape=(), name=\"center_words\", dtype=tf.int32\n",
    "        )\n",
    "        self.target_words = InputLayer(\n",
    "            input_shape=(1,), name=\"target_words\", dtype=tf.int32\n",
    "        )\n",
    "\n",
    "        self.embedding = embedding_lookup(self.embed_size)\n",
    "        self.loss = nce_loss(self.embed_size, self.num_sampled)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"To-Do: Define data flow and return loss\"\"\"\n",
    "        center_words, target_words = inputs[0], inputs[1]\n",
    "        center_words = self.center_words(inputs[0])\n",
    "        target_words = self.target_words(inputs[1])\n",
    "\n",
    "        embedding = self.embedding(center_words)\n",
    "        loss = self.loss([embedding, target_words])\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consruct model, loss, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 09:47:33.185136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.207098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.207133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.207853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.207879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.207896: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.443688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.443729: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.443737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-02 09:47:33.443765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-02 09:47:33.443781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9717 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(embed_size=params[\"embed_size\"], num_sampled=params[\"num_sampled\"])\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(\n",
    "    learning_rate=params[\"learning_rate\"], momentum=0.1, nesterov=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensorflow dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    yield from batch_generator(data_w2id, 2, params[\"batch_size\"])\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    gen,\n",
    "    (tf.int32, tf.int32),\n",
    "    (tf.TensorShape([params[\"batch_size\"]]), tf.TensorShape([params[\"batch_size\"], 1])),\n",
    ").repeat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 09:47:43.262869: W tensorflow/tsl/platform/default/env.cc:299] We are not able to find a directory for temporary files.\n",
      "Verify the directory access and available space under: /tmp. You can also provide a directory for temporary files with the environment variable TMP or TMPDIR. Example under bash: `export TMP=/my_new_temp_directory;`\n",
      "2023-11-02 09:47:43.262925: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-02 09:47:43.262953: W tensorflow/tsl/platform/default/env.cc:299] We are not able to find a directory for temporary files.\n",
      "Verify the directory access and available space under: /tmp. You can also provide a directory for temporary files with the environment variable TMP or TMPDIR. Example under bash: `export TMP=/my_new_temp_directory;`\n",
      "2023-11-02 09:47:43.262971: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-02 09:47:43.848862: W tensorflow/tsl/platform/default/env.cc:299] We are not able to find a directory for temporary files.\n",
      "Verify the directory access and available space under: /tmp. You can also provide a directory for temporary files with the environment variable TMP or TMPDIR. Example under bash: `export TMP=/my_new_temp_directory;`\n",
      "2023-11-02 09:47:43.848902: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-02 09:47:43.906365: W tensorflow/tsl/platform/default/env.cc:299] We are not able to find a directory for temporary files.\n",
      "Verify the directory access and available space under: /tmp. You can also provide a directory for temporary files with the environment variable TMP or TMPDIR. Example under bash: `export TMP=/my_new_temp_directory;`\n",
      "2023-11-02 09:47:43.906413: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-02 09:47:43.966307: W tensorflow/tsl/platform/default/env.cc:299] We are not able to find a directory for temporary files.\n",
      "Verify the directory access and available space under: /tmp. You can also provide a directory for temporary files with the environment variable TMP or TMPDIR. Example under bash: `export TMP=/my_new_temp_directory;`\n",
      "2023-11-02 09:47:43.966355: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-02 09:47:44.022380: W tensorflow/tsl/platform/default/env.cc:299] We are not able to find a directory for temporary files.\n",
      "Verify the directory access and available space under: /tmp. You can also provide a directory for temporary files with the environment variable TMP or TMPDIR. Example under bash: `export TMP=/my_new_temp_directory;`\n",
      "2023-11-02 09:47:44.022440: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000, Loss: 172.81\n",
      "Step 4000, Loss: 28.64\n",
      "Step 6000, Loss: 12.90\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/matcha0714/project/1121_Deep_Learning/Lab10/Lab10_112501533.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matcha0714/project/1121_Deep_Learning/Lab10/Lab10_112501533.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m==\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mtraining_steps\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matcha0714/project/1121_Deep_Learning/Lab10/Lab10_112501533.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matcha0714/project/1121_Deep_Learning/Lab10/Lab10_112501533.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m train_step(center_words, target_words)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matcha0714/project/1121_Deep_Learning/Lab10/Lab10_112501533.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m ((step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mskip_step\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matcha0714/project/1121_Deep_Learning/Lab10/Lab10_112501533.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     template \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mStep \u001b[39m\u001b[39m{:0}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define training function\n",
    "@tf.function\n",
    "def train_step(center_words, target_words):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = word2vec([center_words, target_words])\n",
    "\n",
    "    gradients = tape.gradient(loss, word2vec.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, word2vec.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "\n",
    "\n",
    "# Training\n",
    "x = []\n",
    "y = []\n",
    "for step, (center_words, target_words) in enumerate(dataset):\n",
    "    if step == params[\"training_steps\"]:\n",
    "        break\n",
    "    train_step(center_words, target_words)\n",
    "\n",
    "    if ((step + 1) % params[\"skip_step\"]) == 0:\n",
    "        template = \"Step {:0}, Loss: {:.2f}\"\n",
    "        x.append(step + 1)\n",
    "        y.append(train_loss.result())\n",
    "        print(template.format(step + 1, train_loss.result()))\n",
    "        train_loss.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.plot(x, y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the learned embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding matrix from model weights. > word2vec.weights[0]\n",
    "embedding_matrix = word2vec.weights[0]\n",
    "\n",
    "\n",
    "def plot_with_labels(low_dim_embs, labels):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    plt.figure(figsize=(18, 18), dpi=150)  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y),\n",
    "            xytext=(5, 2),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"right\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "\n",
    "tsne = TSNE(\n",
    "    perplexity=30,\n",
    "    n_components=2,\n",
    "    init=\"pca\",\n",
    "    n_iter=5000,\n",
    "    method=\"exact\",\n",
    "    learning_rate=\"auto\",\n",
    ")\n",
    "plot_only = 400\n",
    "final_embeddings = embedding_matrix\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "labels = [id_to_word[i] for i in range(plot_only)]\n",
    "plot_with_labels(low_dim_embs, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find top-5 nearest neighbors of two words.\n",
    "\n",
    "Words: \"will\", \"western\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy method for calculating the similarity between 2 word\n",
    "def cos_sim(word1, word2):\n",
    "    id1 = word_to_id[word1]\n",
    "    id2 = word_to_id[word2]\n",
    "\n",
    "    vec1 = embedding_matrix[id1].numpy()\n",
    "    vec2 = embedding_matrix[id2].numpy()\n",
    "\n",
    "    return np.dot(vec1, vec2) / (LA.norm(vec1) * LA.norm(vec2))\n",
    "\n",
    "\n",
    "def top_k_nearest(word, k):\n",
    "    vec = embedding_matrix[word_to_id[word]]\n",
    "\n",
    "    # calaulate cosine similarity  of `vec` and all other vocabularies\n",
    "    dot = np.dot(embedding_matrix.numpy(), vec)\n",
    "    embedding_norm = LA.norm(embedding_matrix.numpy(), axis=-1)\n",
    "    vec_norm = LA.norm(vec)\n",
    "    norm_product = embedding_norm * vec_norm\n",
    "    cos_sim = dot / norm_product\n",
    "\n",
    "    # print out top k nearest words\n",
    "    indices = np.argsort(cos_sim)[::-1][:k]\n",
    "    print(\"---top {} nearest words of {}---\".format(k, word))\n",
    "    for idx in indices:\n",
    "        print(id_to_word[idx])\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "top_k_nearest(\"will\", 5)\n",
    "top_k_nearest(\"western\", 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
